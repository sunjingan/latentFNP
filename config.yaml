vnames: &id001
  single_level_vnames:
  - u10
  - v10
  - t2m
  - msl
  multi_level_vnames:
  - z
  - q
  - u
  - v
  - t
  hight_level_list:
  - 50
  - 100
  - 150
  - 200
  - 250
  - 300
  - 400
  - 500
  - 600
  - 700
  - 850
  - 925
  - 1000
dataset:
  train:
    type: era5_npy_f32
    data_dir: 's3://era5_np_float32'
    train_stride: 6
    file_stride: 6
    sample_stride: 1
    vnames: *id001
  valid:
    type: era5_npy_f32
    data_dir: 's3://era5_np_float32'
    train_stride: 6
    file_stride: 6
    sample_stride: 1
    vnames: *id001
dataloader:
  num_workers: 32
  pin_memory: true
  prefetch_factor: 2
  persistent_workers: true
model:
  type: VAE
  params:
    arch: vit_large
    pretrained_model: ""
    patch_size: [4, 4]
    patch_stride: [4, 4]
    in_chans: 69
    out_chans: 69
    kwargs:
      z_dim: 69  
      learnable_pos: true
      window: true
      window_size:
        - [24, 24]
        - [12, 48]
        - [48, 12]
      interval: 4
      drop_path_rate: 0.0
      round_padding: true
      pad_attn_mask: true
      test_pos_mode: learnable_simple_interpolate
      lms_checkpoint_train: true
      img_size: [128, 256]
  criterion: CNPFLoss
  optimizer:
    type: AdamW
    params:
      lr: 1.0e-04
      betas:
      - 0.9
      - 0.9
      weight_decay: 0.01
  lr_scheduler:
    type: OneCycleLR
    params:
      max_lr: 1.0e-4
      pct_start: 0.1
      anneal_strategy: cos
      div_factor: 100
      final_div_factor: 1000